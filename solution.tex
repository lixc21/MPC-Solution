\documentclass[11pt,a4paper]{report}
\usepackage[hmargin=1.25in,vmargin=1in]{geometry}
\usepackage{amsthm}
\usepackage{cite,url,amsmath,amssymb,bm}
\usepackage{algorithm,graphicx,color}

\title{The Solution of Model Predictive Control: Theory, Computation, and Design}
\author{lixc21}
\date{\today}

\begin{document}
\newtheorem*{remark}{Remark}
\theoremstyle{definition}\newtheorem{exercise}{Exercise}[chapter]

\maketitle

\chapter{Getting Started with Model Predictive Control}
\section{Brief Review}
In this section, we just consider state space linear time invariant system with zero steady state.

\paragraph{Lemma 1.3} (LQR convergence). For $(A,B)$ controllable, the infinite LQR gives a convergent closed-loop system.
\begin{proof}
Because $(A,B)$ is controllable, there exists a sequence of $n$ inputs that transfers the state to zero. When $k>n$, we let $u=0$, then the objective function $V(x,u)=\sum_{k=0}^\infty x_k^\top Qx_k+u^\top Ru$ is finite, which implies the optimization problem is feasible. On the other hand, the solution is unique since $R>0$ and the objective function is strict convex with $u$.

So the solution of the LQR problem exists and is unique. This imples to that the objective funtion is non-increasing with time, and we have $x\to 0$, $u\to 0$ as $k\to 0$.
\end{proof}
\begin{remark}
The optimal solution can be calculate from Riccati equation, which is from backward dynamic programming similar to Kalman filter.
\begin{equation}\notag
\begin{aligned}
K&=-(B^\top PB+R)^{-1} B^\top PA\\
P&=Q+A^\top PA-A^\top PB(B^\top PB+R)^{-1}B^\top PA
\end{aligned}
\end{equation}
\end{remark}



\section{The Solution of Exercises}
\begin{exercise} State space form for chemaical reaction model.\newline
    sdf
\end{exercise}


\end{document}

























